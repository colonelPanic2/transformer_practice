{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldavi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Files/Development/AI/Transformers/integrations/twitter_sentiment/checkpoints\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch.utils.data as data\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import sys\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "# from transformer_implementation import *\n",
    "import pandas as pd\n",
    "\n",
    "# NOTE: Setting up a tokenizer to transform the text data into a format that can be fed into the model.\n",
    "# pip install transformers torch (OR pip install transformers tensorflow, if you want to use tensorflow instead)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "root_dir  = 'C:/Files/Development/AI/Transformers/transformer_practice/integrations'\n",
    "\n",
    "# Path to the folder where the datasets are/will be downloaded\n",
    "DATASET_PATH = root_dir+ '/twitter_sentiment/datasets'\n",
    "# Path to the folder where the model checkpoints will be saved\n",
    "CHECKPOINT_PATH = root_dir+ '/twitter_sentiment/checkpoints'\n",
    "\n",
    "print(CHECKPOINT_PATH)\n",
    "\n",
    "# pl.seed_everything(42) # Set the random seed for reproducibility\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# The below code trains a transformer model to answer the question: \"Is this a positive, negative or neutral sentiment?\"\n",
    "\n",
    "sentiment_labels = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Irrelevant': 3\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0eb1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute(\"notebook_filename = '\"+IPython.notebook.notebook_name+\"'\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.display\n",
    "IPython.display.display(IPython.display.Javascript('IPython.notebook.kernel.execute(\"notebook_filename = \\'\"+IPython.notebook.notebook_name+\"\\'\")'))\n",
    "# filename = notebook_filename\n",
    "# filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996fb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformer_implementation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63936b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Files/Development/AI/Transformers/integrations/twitter_sentiment/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldavi\\AppData\\Local\\Temp\\ipykernel_27404\\3117081695.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lambda x: torch.tensor(\n",
      "C:\\Users\\ldavi\\AppData\\Local\\Temp\\ipykernel_27404\\3117081695.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lambda x: torch.tensor(\n",
      "C:\\Users\\ldavi\\AppData\\Local\\Temp\\ipykernel_27404\\3117081695.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lambda x: torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch.utils.data as data\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import sys\n",
    "# try:\n",
    "#     filename = os.path.dirname(__file__)\n",
    "# except:\n",
    "#     filename = 'c:\\Files\\Development\\AI\\Transformers\\integrations\\twitter_sentiment'\n",
    "# sys.path.append(os.path.abspath(os.path.join(filename, '..')))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# NOTE: Setting up a tokenizer to transform the text data into a format that can be fed into the model.\n",
    "# pip install transformers torch (OR pip install transformers tensorflow, if you want to use tensorflow instead)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "root_dir  = 'C:/Files/Development/AI/Transformers/integrations'\n",
    "\n",
    "# Path to the folder where the datasets are/will be downloaded\n",
    "DATASET_PATH = root_dir+ '/twitter_sentiment/datasets'\n",
    "# Path to the folder where the model checkpoints will be saved\n",
    "CHECKPOINT_PATH = root_dir+ '/twitter_sentiment/checkpoints'\n",
    "\n",
    "print(CHECKPOINT_PATH)\n",
    "\n",
    "pl.seed_everything(42) # Set the random seed for reproducibility\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# The below code trains a transformer model to answer the question: \"Is this a positive, negative or neutral sentiment?\"\n",
    "\n",
    "sentiment_labels = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Irrelevant': 3\n",
    "}\n",
    "\n",
    "def path_join(path, fname):\n",
    "    return os.path.abspath(os.path.join(DATASET_PATH, fname)).replace('\\\\', '/')\n",
    "class SentimentDataset(data.Dataset):\n",
    "    def __init__(self, seq_len, num_categories, test_sample_frac, mode, test_rows=None):\n",
    "        super().__init__()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "        # self.size = dataset_size\n",
    "\n",
    "        self.mode = mode.lower().strip()\n",
    "        if mode == \"train\":\n",
    "            self.data = pd.read_csv(path_join(DATASET_PATH, \"twitter_training.csv\")).drop_duplicates().reset_index()\n",
    "            self.data = self.data[~self.data.index.isin(test_rows)]\n",
    "        elif mode == \"validation\":\n",
    "            self.data = pd.read_csv(path_join(DATASET_PATH, \"twitter_validation.csv\")).drop_duplicates().reset_index()\n",
    "        elif mode == \"test\":\n",
    "            self.data = pd.read_csv(path_join(DATASET_PATH, \"twitter_training.csv\")).drop_duplicates().reset_index()\n",
    "            self.data = self.data.sample(n=round(len(self.data)*test_sample_frac), random_state=42)\n",
    "            self.index_vals = self.data.index\n",
    "        self.size = len(self.data)\n",
    "        self.labels = torch.tensor(self.data['sentiment'].map(sentiment_labels).tolist()).unsqueeze(1).unsqueeze(1)\n",
    "        # self.data = torch.tensor(self.data['message'].apply(lambda x: torch.Tensor(tokenizer.encode(str(x), add_special_tokens=True, truncation=True, padding='max_length', max_length=seq_len)).float()).values)\n",
    "        self.data = torch.stack(\n",
    "            self.data['message'].apply(\n",
    "                lambda x: torch.tensor(\n",
    "                    tokenizer.encode(\n",
    "                        str(x),\n",
    "                        add_special_tokens=True,\n",
    "                        truncation=True,\n",
    "                        padding='max_length',\n",
    "                        max_length=seq_len,\n",
    "                        return_tensors='pt'\n",
    "                    ),\n",
    "                    dtype=torch.float32\n",
    "                )\n",
    "            ).tolist()\n",
    "        )\n",
    "\n",
    "        # df_validation = pd.read_csv(os.path.join(DATASET_PATH, \"twitter_validation.csv\")).drop_duplicates()\n",
    "        # # self.data = torch.randint(num_categories, size=(dataset_size, seq_len)) # [dataset_size, seq_len]\n",
    "        # csv_path = os.path.join(DATASET_PATH, \"financial_sentiment_data.csv\")  # Replace with your CSV file path\n",
    "        # df = pd.read_csv(csv_path)\n",
    "        # # seq_len = len(max(df['Sentence'], key=lambda x: len(x)))\n",
    "        # df['Sentence'] = df['Sentence'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, padding='max_length', max_length=seq_len))  # Tokenize the sentences]\n",
    "        # self.data = torch.tensor(df['Sentence'].values, dtype=torch.long)  # Convert DataFrame to torch tensor\n",
    "        # df['Sentiment'] = df['Sentiment'].map(sentiment_labels)  # Map sentiment labels to integers\n",
    "        # self.labels = torch.tensor(df['Sentiment'].values, dtype=torch.long)  # Convert labels to torch tensor\n",
    "\n",
    "    def get_index(self):\n",
    "        return None if self.mode != 'test' else self.index_vals\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            labels = self.labels[idx]\n",
    "        except KeyError:\n",
    "            print(f'KeyError: {idx}\\t|\\t{self.labels.shape}, {self.data.shape}')\n",
    "            raise KeyError\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset = partial(SentimentDataset, 280, 4, 0.1)\n",
    "test_dataset = dataset(\"test\")\n",
    "test_loader  = data.DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = data.DataLoader(dataset(\"train\", test_rows=test_dataset.get_index()), batch_size=128, shuffle=True, drop_last=True, pin_memory=True)\n",
    "val_loader   = data.DataLoader(dataset(\"validation\"), batch_size=128)\n",
    "# inp_data, labels = train_loader.dataset[0]\n",
    "# print(f\"Input data: {inp_data}\\nLabels:     {labels}\")\n",
    "\n",
    "class SentimentPredictor(TransformerPredictor):\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        inp_data, labels = batch\n",
    "\n",
    "        # inp_data = F.one_hot(inp_data, num_classes=self.hparams.num_classes).float()\n",
    "        preds = self.forward(inp_data, add_positional_encoding=True)\n",
    "        # NOTE: by transforming the predictions and labels as shown below, we make the loss function treat each token prediction independently when\n",
    "        # calculating the loss. \n",
    "        # preds.view(-1, preds.size(-1)): [batch_size, seq_len, num_classes] => [batch_size * seq_len, num_classes]\n",
    "        # labels.view(-1): [batch_size, seq_len] => [batch_size * seq_len]\n",
    "        loss = F.cross_entropy(preds.view(-1, preds.size(-1)), labels.view(-1))\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log(f\"{mode}_loss\", loss)\n",
    "        self.log(f\"{mode}_acc\", acc)\n",
    "        return loss, acc\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self._calculate_loss(batch, mode=\"train\")\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"test\")\n",
    "\n",
    "\n",
    "def train_sentiment(**kwargs):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"twitter_sentiment\")\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    # NOTE: The gradient_clip_val argument prevents exploding gradients during backpropagation\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=10,\n",
    "                         gradient_clip_val=5\n",
    "                         )\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"SentimentTask.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model. Loading...\")\n",
    "        model = SentimentPredictor.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        model = SentimentPredictor(max_iters=trainer.max_epochs*len(train_loader), **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    result = {\"test_acc\": test_result[0][\"test_acc\"], \"val_acc\": val_result[0][\"test_acc\"]}\n",
    "    model = model.to(device)\n",
    "    return model, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19146ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, result = \u001b[43mtrain_sentiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m280\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2e10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m  \u001b[49m\u001b[32;43m2e5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_categories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2e3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#     max_seq_len=1\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mVal accuracy:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[32m100.0\u001b[39m\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39mresult[\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m4.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 161\u001b[39m, in \u001b[36mtrain_sentiment\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m     model = SentimentPredictor.load_from_checkpoint(pretrained_filename)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     model = \u001b[43mSentimentPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     trainer.fit(model, train_loader, val_loader)\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# Test best model on validation and test set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Files\\Development\\AI\\Transformers\\integrations\\twitter_sentiment\\transformer_implementation.py:186\u001b[39m, in \u001b[36mTransformerPredictor.__init__\u001b[39m\u001b[34m(self, input_dim, model_dim, num_classes, num_heads, num_layers, lr, warmup, max_iters, dropout, input_dropout)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m.save_hyperparameters()\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Files\\Development\\AI\\Transformers\\integrations\\twitter_sentiment\\transformer_implementation.py:192\u001b[39m, in \u001b[36mTransformerPredictor._create_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# Input dim -> Model dim (length of the vector representing each token)\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_net = nn.Sequential(\n\u001b[32m    191\u001b[39m         nn.Dropout(\u001b[38;5;28mself\u001b[39m.hparams.input_dropout),\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     )\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# Positional encoding for sequences\u001b[39;00m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m.PositionalEncoding = PositionalEncoding(\u001b[38;5;28mself\u001b[39m.hparams.model_dim)\u001b[38;5;66;03m#, max_seq_len=self.hparams.max_seq_len)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:106\u001b[39m, in \u001b[36mLinear.__init__\u001b[39m\u001b[34m(self, in_features, out_features, bias, device, dtype)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.in_features = in_features\n\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.out_features = out_features\n\u001b[32m    105\u001b[39m \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m )\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "\u001b[31mTypeError\u001b[39m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model, result = train_sentiment(\n",
    "    input_dim = 280,\n",
    "    model_dim = 2e10,\n",
    "    num_heads =  2e5,\n",
    "    num_classes = train_loader.dataset.num_categories,\n",
    "    num_layers = 2e3,\n",
    "    dropout = 0.1,\n",
    "    lr = 5e-2,\n",
    "    warmup = 50\n",
    ")\n",
    "#     max_seq_len=1\n",
    "# )\n",
    "\n",
    "\n",
    "print(f\"\\nVal accuracy:  {(100.0 * result['val_acc']):4.2f}%\")\n",
    "print(f\"Test accuracy: {(100.0 * result['test_acc']):4.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2bb2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Files/Development/AI/Transformers/integrations/twitter_sentiment/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldavi\\AppData\\Local\\Temp\\ipykernel_20760\\3347688793.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lambda x: torch.tensor(\n",
      "C:\\Users\\ldavi\\AppData\\Local\\Temp\\ipykernel_20760\\3347688793.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lambda x: torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: tensor([[  101, 10047,  2893,  2006,  3675,  8653,  1998,  1045,  2097,  4028,\n",
      "          2017,  2035,  1010,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "Labels:     0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldavi\\AppData\\Local\\Temp\\ipykernel_20760\\3347688793.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lambda x: torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch.utils.data as data\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "from transformer_implementation import *\n",
    "import pandas as pd\n",
    "\n",
    "# NOTE: Setting up a tokenizer to transform the text data into a format that can be fed into the model.\n",
    "# pip install transformers torch (OR pip install transformers tensorflow, if you want to use tensorflow instead)\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "EMBEDDING_LAYER = model.embeddings.word_embeddings\n",
    "input_dim = TOKENIZER.vocab_size # 30522\n",
    "\n",
    "# def embed_text(text, truncation=True, padding='max_length', max_length=None, return_tensors='pt'):\n",
    "#     if padding == 'max_length' and truncation is False and max_length is not None:\n",
    "#         tokens = TOKENIZER(text, return_tensors=return_tensors, padding=padding, max_length=max_length)\n",
    "#     elif padding == 'max_length' and truncation is True and max_length is not None:\n",
    "#         tokens = TOKENIZER(text, return_tensors=return_tensors, truncation=truncation, padding=padding, max_length=max_length)\n",
    "#     else:\n",
    "#         tokens = TOKENIZER(text, return_tensors=return_tensors)\n",
    "#     input_ids = tokens['input_ids']\n",
    "#     embeddings = EMBEDDING_LAYER(input_ids)\n",
    "#     return embeddings\n",
    "def embed_tokens(tokens, truncation=True, padding='max_length', max_length=None, return_tensors='pt'):\n",
    "    # input_ids = tokens['input_ids']\n",
    "    # embeddings = EMBEDDING_LAYER(input_ids)\n",
    "    embeddings = EMBEDDING_LAYER(tokens)\n",
    "    return embeddings.squeeze(0)\n",
    "# import string\n",
    "# class Tokenizer():\n",
    "#     def __init__(self):\n",
    "#         self.vocab = {c: i for i, c in enumerate(string.printable)}\n",
    "#         self.vocab_size = len(self.vocab)\n",
    "#     def encode(self, text, add_special_tokens=False, truncation=False, padding=False, max_length=None, return_tensors=None):\n",
    "#         tokens = [self.vocab.get(c, -1) for c in text if c in self.vocab]\n",
    "#         if truncation and max_length is not None:\n",
    "#             tokens = tokens[:max_length]\n",
    "#         if padding and max_length is not None:\n",
    "#             tokens += [0] * (max_length - len(tokens))\n",
    "#         # if add_special_tokens:\n",
    "#         #     tokens = [self.vocab['[CLS]']] + tokens + [self.vocab['[SEP]']]\n",
    "#         if return_tensors == 'pt':\n",
    "#             return torch.tensor(tokens, dtype=torch.long)\n",
    "#         return tokens\n",
    "# tokenizer = Tokenizer()\n",
    "# input_dim = tokenizer.vocab_size # 62\n",
    "root_dir  = 'C:/Files/Development/AI/Transformers/integrations'\n",
    "\n",
    "BATCH_SIZE = int(input(\"Enter batch size: \"))\n",
    "\n",
    "\n",
    "# Path to the folder where the datasets are/will be downloaded\n",
    "DATASET_PATH = root_dir+ '/twitter_sentiment/datasets'\n",
    "# Path to the folder where the model checkpoints will be saved\n",
    "CHECKPOINT_PATH = root_dir+ '/twitter_sentiment/checkpoints'\n",
    "\n",
    "print(CHECKPOINT_PATH)\n",
    "\n",
    "pl.seed_everything(42) # Set the random seed for reproducibility\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# The below code trains a transformer model to answer the question: \"Is this a positive, negative or neutral sentiment?\"\n",
    "\n",
    "sentiment_labels = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Irrelevant': 3\n",
    "}\n",
    "\n",
    "def path_join(path, fname):\n",
    "    return os.path.abspath(os.path.join(DATASET_PATH, fname)).replace('\\\\', '/')\n",
    "class SentimentDataset(data.Dataset):\n",
    "    def __init__(self, seq_len, num_categories, test_sample_frac, mode, test_rows=None):\n",
    "        super().__init__()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "        # self.size = dataset_size\n",
    "\n",
    "        self.mode = mode.lower().strip()\n",
    "        if mode == \"train\":\n",
    "            self.data = pd.read_csv(path_join(DATASET_PATH, \"twitter_training.csv\")).drop_duplicates().reset_index()\n",
    "            self.data = self.data[~self.data.index.isin(test_rows)]\n",
    "        elif mode == \"validation\":\n",
    "            self.data = pd.read_csv(path_join(DATASET_PATH, \"twitter_validation.csv\")).drop_duplicates().reset_index()\n",
    "        elif mode == \"test\":\n",
    "            self.data = pd.read_csv(path_join(DATASET_PATH, \"twitter_training.csv\")).drop_duplicates().reset_index()\n",
    "            self.data = self.data.sample(n=round(len(self.data)*test_sample_frac), random_state=42)\n",
    "            self.index_vals = self.data.index\n",
    "        self.size = len(self.data)\n",
    "        self.labels = torch.tensor(self.data['sentiment'].map(sentiment_labels).tolist())#.unsqueeze(1).unsqueeze(1)\n",
    "        # self.data = torch.tensor(self.data['message'].apply(lambda x: torch.Tensor(tokenizer.encode(str(x), add_special_tokens=True, truncation=True, padding='max_length', max_length=seq_len)).float()).values)\n",
    "        # self.data = torch.stack(\n",
    "        #     self.data['message'].apply(\n",
    "        #         lambda x: torch.tensor(\n",
    "        #             tokenizer.encode(\n",
    "        #                 str(x),\n",
    "        #                 add_special_tokens=True,\n",
    "        #                 truncation=True,\n",
    "        #                 padding='max_length',\n",
    "        #                 max_length=seq_len,\n",
    "        #                 return_tensors='pt'\n",
    "        #             ),\n",
    "        #             dtype=torch.float32\n",
    "        #         )\n",
    "        #     ).tolist()\n",
    "        # )\n",
    "        # self.data = torch.stack(\n",
    "        #     self.data['message'].apply(\n",
    "        #         lambda x: embed_text(\n",
    "        #             str(x),\n",
    "        #             truncation=True,\n",
    "        #             padding='max_length',\n",
    "        #             max_length=seq_len,\n",
    "        #             return_tensors='pt'\n",
    "        #         )\n",
    "        #     ).tolist()\n",
    "        # )\n",
    "        self.data = torch.stack(\n",
    "            self.data['message'].apply(\n",
    "                lambda x: torch.tensor(\n",
    "                    TOKENIZER.encode(\n",
    "                        str(x),\n",
    "                        add_special_tokens=True,\n",
    "                        truncation=True,\n",
    "                        padding='max_length',\n",
    "                        max_length=seq_len,\n",
    "                        return_tensors='pt'\n",
    "                    ),\n",
    "                    dtype=torch.long\n",
    "                )\n",
    "            ).tolist()\n",
    "        )\n",
    "        # df_validation = pd.read_csv(os.path.join(DATASET_PATH, \"twitter_validation.csv\")).drop_duplicates()\n",
    "        # # self.data = torch.randint(num_categories, size=(dataset_size, seq_len)) # [dataset_size, seq_len]\n",
    "        # csv_path = os.path.join(DATASET_PATH, \"financial_sentiment_data.csv\")  # Replace with your CSV file path\n",
    "        # df = pd.read_csv(csv_path)\n",
    "        # # seq_len = len(max(df['Sentence'], key=lambda x: len(x)))\n",
    "        # df['Sentence'] = df['Sentence'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, padding='max_length', max_length=seq_len))  # Tokenize the sentences]\n",
    "        # self.data = torch.tensor(df['Sentence'].values, dtype=torch.long)  # Convert DataFrame to torch tensor\n",
    "        # df['Sentiment'] = df['Sentiment'].map(sentiment_labels)  # Map sentiment labels to integers\n",
    "        # self.labels = torch.tensor(df['Sentiment'].values, dtype=torch.long)  # Convert labels to torch tensor\n",
    "\n",
    "    def get_index(self):\n",
    "        return None if self.mode != 'test' else self.index_vals\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # try:\n",
    "        #     labels = self.labels[idx]\n",
    "        # except KeyError:\n",
    "        #     print(f'KeyError: {idx}\\t|\\t{self.labels.shape}, {self.data.shape}')\n",
    "        #     raise KeyError\n",
    "        # data = embed_tokens(self.data[idx])\n",
    "        # return data, self.labels[idx]\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset = partial(SentimentDataset, 280, 4, 0.1)\n",
    "test_dataset = dataset(\"test\")\n",
    "test_loader  = data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "train_loader = data.DataLoader(dataset(\"train\", test_rows=test_dataset.get_index()), batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n",
    "val_loader   = data.DataLoader(dataset(\"validation\"), batch_size=BATCH_SIZE)\n",
    "inp_data, labels = train_loader.dataset[0]\n",
    "print(f\"Input data: {inp_data}\\nLabels:     {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b17fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f083898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 280]), torch.Size([280, 768]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_data.shape, embed_tokens(inp_data).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
